#+startup: beamer
#+TITLE: Monte Carlo parameter estimation in the Lorenz 63 system
#+AUTHOR: Noah D. Brenowitz
#+OPTIONS: h:2
#+LaTeX_CLASS: beamer


* Codes 							   :noexport:
#+BEGIN_SRC emacs-lisp
  (require 'ob-dot)
  (setq org-confirm-babel-evaluate nil)
#+END_SRC

#+RESULTS:

* Introduction
** Introduction							   :noexport:

- The point of this final project is to learn parameters in Lorenz63
  using monte carlo methods. The approach taken is to formulate a
  Hamiltonian using the dynamic residuals, and then sample from the
  corresponding Gibbs distribution.

- Another similar idea is to estimate the state of the system given
  noisy observations (e.g. data assimilation).


** Lorenz63 system
This system is one of the earliest examples of what would later become
known as /chaotic/ dynamical systems. It is obtained by projection of
the Rayleigh-Benard equations for convection of a thin layer onto
three orthogonal modes. The system is given by
\begin{align}
\dot{X} &= \sigma(Y-X)\\
\dot{Y} &= -XZ + rX - Y\\
\dot{Z} &= XY - bZ.
\end{align}
The parameters used by Lorenz are $\sigma = 10$, $b=8/3$ and $r=28$.

** 

[[file:lorenz63.pdf]]

* Parameter Fitting procedure
** Notation
- Let $U$ be given by the dynamics 
  \[ \dot{U} =  F(U; \theta) + \epsilon \dot{W}\]
  where $\theta$ is some set of parameters.

- Let $\Psi_t^{\theta}$ be the /propagator/, defined by
\[\Psi_t^{\theta}U(s) = U(t+s).\]

- /Temporal grid/: Let $T > 0$, $N$, and define $\tau = T / (N+1)$. Then, a temporal grid
  $t_j=j \tau$ can be defined for $j=0...N$. 

** Dynamic Residuals
 Given a set of point estimates $U_j$ and parameters, define the dynamic
residual for a time $t_j$ to be
\[ e_j(\theta) := e(U_{j-1}, U_j, \theta) :=  \Psi_{\tau}^{\theta} U_{j-1} - U_j.\]

Then, a sensible way to choose the parameters is so that they minimize
\[ \sum_{j=1}^{N}|e_j|^2.\]

Because $\theta$ is a potentially high dimensional object, Monte Carlo
techniques can be used to perform this optimization.

* Sampling strategy

** Equilibrium distribution

- Vector of parameters $\theta = [\sigma, r, b]$

- Generate samples $\theta_k$ from
  \[ f(\theta) \propto  \exp \left( -\frac{\beta}{N}\sum_{j=1}^{N}|e_j(\theta)|^2 \right).\]
- The mode of $f(\theta)$ is the value that minimizes the dynamic residuals
** Data assimilation						   :noexport:
Note that $U_{j}$ is only in $e_j$ and $e_{j-1}$, this can be used to
simplify the optimization problem, and suggests some sort of
resampling technique.
** Proposal Distribution
  
- Independent gaussian proposal function:
  \[P(\theta_{0}, \theta_1) \propto \exp \left( -\frac{1}{2} (\theta_1
  -\theta_0)^T C^{-1} (\theta_1 -\theta_0) \right) \]
- Covariance matrix: $C_{11} = .5^2$, $C_{22} = .1^2$, $C_{33}=1.0^2$,
  $C_{ij} = 0$ if $i\ne j$.
  
** Acceptance Probability 

Metropolis-Hastings acceptance probability:
\[ A(\theta_0, \theta_1 ) = \min \left\{1, \frac{f(\theta_1)
P(\theta_1, \theta_0)}{f(\theta_0) P(\theta_0, \theta_1)}  \right\}  \]
   
  
* Code Architecture

** Languages and Libraries
- Language: C++ for sampler, Python for plotting/analysis
- C++ Libraries:
  - [[http://arma.sourceforge.net][Armadillo++]] for convenient vector arithmetic
  - [[http://www.gnu.org/software/gsl/gsl.html][GNU Scientific Library]] for random number generation

** Code Architecture						   :noexport:

- The integrator for the dynamical system is defined in [[file:src/integrate.cpp]].
  - Second order explicit predictor/corrector method for deterministic dynamics
  - Forward Euler for the stochastic terms
- [[file:src/equil.cpp]] contains the equilibrium distribution
- The basic proposal distribution and metropolis acceptance function
  are defined in [[file:src/mcmc.cpp]].
- [[file:src/param_search.cpp]] contains the parameter searching method.
  
** Code Architecture

#+BEGIN_SRC dot :file dependency.pdf :exports results
  digraph thing {
   "param_search.cpp" -> "equil.cpp";
   "param_search.cpp" -> "mcmc.cpp";
   "equil.cpp" -> "integrate.cpp";
   "param_search.cpp" -> "integrate.cpp";
   
  }
#+END_SRC

#+RESULTS:
[[file:dependency.pdf]]



   


* Results
** $\tau = .5$ Traces

[[file:{tau-.5-0}.pdf]]   

** $\tau = .5$ Distributions
[[file:{tau-.5-1}.pdf]]   

** $\tau = .5$ Autocorrelation functions
[[file:{tau-.5-2}.pdf]]   

   
** $\tau = 1.0$ Traces

[[file:{tau-1.0-0}.pdf]]   


** $\tau = 5.0$ Traces

[[file:{tau5.0-0}.pdf]]   

** $\tau = 5.0$ Distributions
[[file:{tau5.0-1}.pdf]]   



** Reducing $\beta$ gives large drift and autocorrelations

[[file:lowbeta-0.pdf]]


** Model Error can help

- Let $\epsilon = 5.0$
  
[[file:lorenz63_noisy.pdf]]

** Model error can help a little

[[file:noisy-0.pdf]]
  
** Model error can help a little

[[file:noisy-1.pdf]]
  

* Conclusions

** Conclusions

- Using the dynamic residuals method to find parameters works well for
  short observations times $\tau \leq .5$.
- MCMC performance is very poor for larger $\tau$.
- Making a model error can help regularize the fit
- $\sigma$ is the most difficult parameter to estimate

** Future Directions

- Use dynamic residuals might work better for the data assimilation problem
- Parameter fitting might be better done by matching equilbrium /statistics/ 
  of the attractor rather than exact paths.
